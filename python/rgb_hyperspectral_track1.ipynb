{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rgb_hyperspectral_track1.ipynb","provenance":[{"file_id":"1XrR8d3o05c22Vt_nIGbXp2V8W3TNNIDT","timestamp":1633368096569}],"collapsed_sections":[],"mount_file_id":"1z2a1ZU-yTjpkvX_1FNPzbBXyX5_anaiM","authorship_tag":"ABX9TyPUfKLkB97u7ZHl8XDzVeSr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6IzQdi9zVMHi","executionInfo":{"status":"ok","timestamp":1638054380427,"user_tz":480,"elapsed":11715,"user":{"displayName":"hawksFTW","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10550048566476126053"}},"outputId":"8b75ebef-3894-4c51-cbcf-9438b65a1297"},"source":["import argparse\n","import os\n","import torch\n","import numpy as np\n","import cv2\n","!pip install hdf5storage\n","import hdf5storage as hdf5\n","import sys\n","\n","\n","\n"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting hdf5storage\n","  Downloading hdf5storage-0.1.18-py2.py3-none-any.whl (53 kB)\n","\u001b[K     |████████████████████████████████| 53 kB 759 kB/s \n","\u001b[?25hRequirement already satisfied: h5py>=2.1 in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (3.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (1.19.5)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.1->hdf5storage) (1.5.2)\n","Installing collected packages: hdf5storage\n","Successfully installed hdf5storage-0.1.18\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"91X1IdklR8ag","executionInfo":{"status":"ok","timestamp":1638054878822,"user_tz":480,"elapsed":26618,"user":{"displayName":"hawksFTW","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10550048566476126053"}},"outputId":"50a5d68c-4f74-403e-c453-720cc64fa5c6"},"source":["sys.path.insert(0,\"/content/drive/My Drive/Hyperspectral\")\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","os.chdir(\"/content/gdrive/MyDrive/Hyperspectral/\")\n","print(os.getcwd())\n","import utils_hp as utils\n","import dataset"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","/content/gdrive/MyDrive/Hyperspectral\n"]}]},{"cell_type":"markdown","metadata":{"id":"KNBIww-dkxyN"},"source":["# New Section"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y2Uro-ZngKbT","executionInfo":{"status":"ok","timestamp":1638055453581,"user_tz":480,"elapsed":568446,"user":{"displayName":"hawksFTW","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10550048566476126053"}},"outputId":"a8687edd-0d9d-416d-d9d7-dba00095b1f5"},"source":["#if __name__ == \"__main__\":\n","    # ----------------------------------------\n","    #        Initialize the parameters\n","    # ----------------------------------------\n","%tb\n","parser = argparse.ArgumentParser()\n","# Pre-train, saving, and loading parameters\n","parser.add_argument('--pre_train', type = bool, default = True, help = 'pre_train or not')\n","parser.add_argument('--test_batch_size', type = int, default = 1, help = 'size of the testing batches for single GPU')\n","parser.add_argument('--num_workers', type = int, default = 2, help = 'number of cpu threads to use during batch generation')\n","parser.add_argument('--val_path', type = str, default = './test', help = 'saving path that is a folder')\n","parser.add_argument('--task_name', type = str, default = 'track2', help = 'task name for loading networks, saving, and log')\n","# Network initialization parameters\n","parser.add_argument('--pad', type = str, default = 'reflect', help = 'pad type of networks')\n","parser.add_argument('--activ', type = str, default = 'lrelu', help = 'activation type of networks')\n","parser.add_argument('--norm', type = str, default = 'none', help = 'normalization type of networks')\n","parser.add_argument('--in_channels', type = int, default = 3, help = 'input channels for generator')\n","parser.add_argument('--out_channels', type = int, default = 31, help = 'output channels for generator')\n","parser.add_argument('--start_channels', type = int, default = 64, help = 'start channels for generator')\n","parser.add_argument('--init_type', type = str, default = 'xavier', help = 'initialization type of generator')\n","parser.add_argument('--init_gain', type = float, default = 0.02, help = 'initialization gain of generator')\n","# Dataset parameters\n","parser.add_argument('--baseroot', type = str, default = './NTIRE2020_Test_Clean', help = 'baseroot')\n","# NTIRE2020_Validation_Clean    NTIRE2020_Validation_RealWorld\n","opt = parser.parse_args(args=[])\n","\n","# ----------------------------------------\n","#                   Test\n","# ----------------------------------------\n","load_net_name_list = []\n","load_net_name_list.append('./track1/code1_320_G_epoch9000_bs4.pth')\n","load_net_name_list.append('./track1/code1_384_G_epoch6000_bs4.pth')\n","load_net_name_list.append('./track1/code1_bs2_G_epoch8000_bs2.pth')\n","load_net_name_list.append('./track1/code1_bs4_G_epoch9000_bs4.pth')\n","load_net_name_list.append('./track1/code1_first_G_epoch10000_bs8.pth')\n","load_net_name_list.append('./track1/code1_G_epoch9000_bs8.pth')\n","load_net_name_list.append('./track1/code1_second_G_epoch8000_bs8.pth')\n","load_net_name_list.append('./track1/code2_G_epoch7000_bs8.pth')\n","\n","for i, name in enumerate(load_net_name_list):\n","    if i < 7:\n","        # Initialize\n","        generator = utils.create_generator_val1(opt, name).cuda()\n","        test_dataset = dataset.HS_multiscale_ValDSet(opt)\n","        print(test_dataset.imglist)\n","        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = opt.test_batch_size, shuffle = False, num_workers = opt.num_workers, pin_memory = True)\n","        sample_folder = os.path.join(opt.val_path, opt.task_name, str(i))\n","        utils.check_path(sample_folder)\n","        print('Network name: %s; The %d-th iteration' % (name, i))\n","\n","        # forward\n","        for j, (img1, img2, path) in enumerate(test_loader):\n","            # To device\n","            img1 = img1.cuda()\n","            img2 = img2.cuda()\n","            path = path[0]\n","            print(opt.task_name, i, path)\n","\n","            # Forward propagation\n","            with torch.no_grad():\n","                out1 = generator(img1) # [0:480, 0:512, :], [1, 31, 480, 512]\n","                out2 = generator(img2) # [2:482, 0:512, :], [1, 31, 480, 512]\n","            out = torch.cat((out1, out2[:, :, 478:, :]), 2)\n","\n","            # Save\n","            out = out.clone().data.permute(0, 2, 3, 1).cpu().numpy()[0, :, :, :].astype(np.float64)\n","            save_img_name = path[:12] + '.mat'\n","            save_img_path = os.path.join(sample_folder, save_img_name)\n","            hdf5.write(data = out, path = 'cube', filename = save_img_path, matlab_compatible = True)\n","            #out[:,:,0:31]\n","            \n","\n","\n","    if i == 7:\n","        # Initialize\n","        generator = utils.create_generator_val2(opt, name).cuda()\n","        test_dataset = dataset.HS_multiscale_ValDSet(opt)\n","        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = opt.test_batch_size, shuffle = False, num_workers = opt.num_workers, pin_memory = True)\n","        sample_folder = os.path.join(opt.val_path, opt.task_name, str(i))\n","        utils.check_path(sample_folder)\n","        print('Network name: %s; The %d-th iteration' % (name, i))\n","\n","        # forward\n","        for j, (img1, img2, path) in enumerate(test_loader):\n","            # To device\n","            img1 = img1.cuda()\n","            #print(img1)\n","            img2 = img2.cuda()\n","            #print(img2)\n","            path = path[0]\n","            print(opt.task_name, i, path)\n","\n","            # Forward propagation\n","            with torch.no_grad():\n","                out1 = generator(img1) # [0:480, 0:512, :], [1, 31, 480, 512]\n","                out2 = generator(img2) # [2:482, 0:512, :], [1, 31, 480, 512]\n","            out = torch.cat((out1, out2[:, :, 478:, :]), 2)\n","            #print(type(out))\n","\n","            # Save\n","            out = out.clone().data.permute(0, 2, 3, 1).cpu().numpy()[0, :, :, :].astype(np.float64)\n","            save_img_name = path[:12] + '.mat' #.npy for array\n","            save_img_path = os.path.join(sample_folder, save_img_name)\n","            print(save_img_path)\n","            hdf5.write(data = out, path = 'cube', filename = save_img_path, matlab_compatible = True)\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["No traceback available to show.\n"]},{"output_type":"stream","name":"stdout","text":["Generator is loaded!\n","['t125.jpeg', 't126.jpeg', 't127.jpeg', 't128.jpeg', 't129.jpeg', 't130.jpeg', 't131.jpeg', 't132.jpeg', 't134.jpeg', 't135.jpeg', 't136.jpeg', 't137.jpeg', 't138.jpeg']\n","Network name: ./track1/code1_320_G_epoch9000_bs4.pth; The 0-th iteration\n","track2 0 t125.jpeg\n","track2 0 t126.jpeg\n","track2 0 t127.jpeg\n","track2 0 t128.jpeg\n","track2 0 t129.jpeg\n","track2 0 t130.jpeg\n","track2 0 t131.jpeg\n","track2 0 t132.jpeg\n","track2 0 t134.jpeg\n","track2 0 t135.jpeg\n","track2 0 t136.jpeg\n","track2 0 t137.jpeg\n","track2 0 t138.jpeg\n","Generator is loaded!\n","['t125.jpeg', 't126.jpeg', 't127.jpeg', 't128.jpeg', 't129.jpeg', 't130.jpeg', 't131.jpeg', 't132.jpeg', 't134.jpeg', 't135.jpeg', 't136.jpeg', 't137.jpeg', 't138.jpeg']\n","Network name: ./track1/code1_384_G_epoch6000_bs4.pth; The 1-th iteration\n","track2 1 t125.jpeg\n","track2 1 t126.jpeg\n","track2 1 t127.jpeg\n","track2 1 t128.jpeg\n","track2 1 t129.jpeg\n","track2 1 t130.jpeg\n","track2 1 t131.jpeg\n","track2 1 t132.jpeg\n","track2 1 t134.jpeg\n","track2 1 t135.jpeg\n","track2 1 t136.jpeg\n","track2 1 t137.jpeg\n","track2 1 t138.jpeg\n","Generator is loaded!\n","['t125.jpeg', 't126.jpeg', 't127.jpeg', 't128.jpeg', 't129.jpeg', 't130.jpeg', 't131.jpeg', 't132.jpeg', 't134.jpeg', 't135.jpeg', 't136.jpeg', 't137.jpeg', 't138.jpeg']\n","Network name: ./track1/code1_bs2_G_epoch8000_bs2.pth; The 2-th iteration\n","track2 2 t125.jpeg\n","track2 2 t126.jpeg\n","track2 2 t127.jpeg\n","track2 2 t128.jpeg\n","track2 2 t129.jpeg\n","track2 2 t130.jpeg\n","track2 2 t131.jpeg\n","track2 2 t132.jpeg\n","track2 2 t134.jpeg\n","track2 2 t135.jpeg\n","track2 2 t136.jpeg\n","track2 2 t137.jpeg\n","track2 2 t138.jpeg\n","Generator is loaded!\n","['t125.jpeg', 't126.jpeg', 't127.jpeg', 't128.jpeg', 't129.jpeg', 't130.jpeg', 't131.jpeg', 't132.jpeg', 't134.jpeg', 't135.jpeg', 't136.jpeg', 't137.jpeg', 't138.jpeg']\n","Network name: ./track1/code1_bs4_G_epoch9000_bs4.pth; The 3-th iteration\n","track2 3 t125.jpeg\n","track2 3 t126.jpeg\n","track2 3 t127.jpeg\n","track2 3 t128.jpeg\n","track2 3 t129.jpeg\n","track2 3 t130.jpeg\n","track2 3 t131.jpeg\n","track2 3 t132.jpeg\n","track2 3 t134.jpeg\n","track2 3 t135.jpeg\n","track2 3 t136.jpeg\n","track2 3 t137.jpeg\n","track2 3 t138.jpeg\n","Generator is loaded!\n","['t125.jpeg', 't126.jpeg', 't127.jpeg', 't128.jpeg', 't129.jpeg', 't130.jpeg', 't131.jpeg', 't132.jpeg', 't134.jpeg', 't135.jpeg', 't136.jpeg', 't137.jpeg', 't138.jpeg']\n","Network name: ./track1/code1_first_G_epoch10000_bs8.pth; The 4-th iteration\n","track2 4 t125.jpeg\n","track2 4 t126.jpeg\n","track2 4 t127.jpeg\n","track2 4 t128.jpeg\n","track2 4 t129.jpeg\n","track2 4 t130.jpeg\n","track2 4 t131.jpeg\n","track2 4 t132.jpeg\n","track2 4 t134.jpeg\n","track2 4 t135.jpeg\n","track2 4 t136.jpeg\n","track2 4 t137.jpeg\n","track2 4 t138.jpeg\n","Generator is loaded!\n","['t125.jpeg', 't126.jpeg', 't127.jpeg', 't128.jpeg', 't129.jpeg', 't130.jpeg', 't131.jpeg', 't132.jpeg', 't134.jpeg', 't135.jpeg', 't136.jpeg', 't137.jpeg', 't138.jpeg']\n","Network name: ./track1/code1_G_epoch9000_bs8.pth; The 5-th iteration\n","track2 5 t125.jpeg\n","track2 5 t126.jpeg\n","track2 5 t127.jpeg\n","track2 5 t128.jpeg\n","track2 5 t129.jpeg\n","track2 5 t130.jpeg\n","track2 5 t131.jpeg\n","track2 5 t132.jpeg\n","track2 5 t134.jpeg\n","track2 5 t135.jpeg\n","track2 5 t136.jpeg\n","track2 5 t137.jpeg\n","track2 5 t138.jpeg\n","Generator is loaded!\n","['t125.jpeg', 't126.jpeg', 't127.jpeg', 't128.jpeg', 't129.jpeg', 't130.jpeg', 't131.jpeg', 't132.jpeg', 't134.jpeg', 't135.jpeg', 't136.jpeg', 't137.jpeg', 't138.jpeg']\n","Network name: ./track1/code1_second_G_epoch8000_bs8.pth; The 6-th iteration\n","track2 6 t125.jpeg\n","track2 6 t126.jpeg\n","track2 6 t127.jpeg\n","track2 6 t128.jpeg\n","track2 6 t129.jpeg\n","track2 6 t130.jpeg\n","track2 6 t131.jpeg\n","track2 6 t132.jpeg\n","track2 6 t134.jpeg\n","track2 6 t135.jpeg\n","track2 6 t136.jpeg\n","track2 6 t137.jpeg\n","track2 6 t138.jpeg\n","Generator is loaded!\n","Network name: ./track1/code2_G_epoch7000_bs8.pth; The 7-th iteration\n","track2 7 t125.jpeg\n","./test/track2/7/t125.jpeg.mat\n","track2 7 t126.jpeg\n","./test/track2/7/t126.jpeg.mat\n","track2 7 t127.jpeg\n","./test/track2/7/t127.jpeg.mat\n","track2 7 t128.jpeg\n","./test/track2/7/t128.jpeg.mat\n","track2 7 t129.jpeg\n","./test/track2/7/t129.jpeg.mat\n","track2 7 t130.jpeg\n","./test/track2/7/t130.jpeg.mat\n","track2 7 t131.jpeg\n","./test/track2/7/t131.jpeg.mat\n","track2 7 t132.jpeg\n","./test/track2/7/t132.jpeg.mat\n","track2 7 t134.jpeg\n","./test/track2/7/t134.jpeg.mat\n","track2 7 t135.jpeg\n","./test/track2/7/t135.jpeg.mat\n","track2 7 t136.jpeg\n","./test/track2/7/t136.jpeg.mat\n","track2 7 t137.jpeg\n","./test/track2/7/t137.jpeg.mat\n","track2 7 t138.jpeg\n","./test/track2/7/t138.jpeg.mat\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GUhVZWkV3Svi","executionInfo":{"status":"ok","timestamp":1636829288889,"user_tz":480,"elapsed":7332,"user":{"displayName":"hawksFTW","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10550048566476126053"}},"outputId":"807c8ece-72ff-44ba-fcf4-c4b49c4b8b54"},"source":["in_path = './test/track1/0/output'\n","file_list_1 = []\n","for filename in os.listdir(in_path):\n","    split_list = []\n","    spectral = hdf5.loadmat(in_path + \"/\" + filename)\n","    #removing comments\n","    #img = spectral['cube']  # 31 channels (482,512,31)\n","    #print(img.shape)\n","    #print(img.dtype)\n","    split_path = in_path + '_split'\n","    if not os.path.exists(split_path):\n","        os.makedirs(split_path)\n","    for i in range(31):\n","        img = spectral['cube'][:, :, i]\n","        a = (img * 255).astype(np.uint8)\n","        new_dir = filename.replace('.mat', '')\n","        dir_path_s = split_path + '/' +new_dir\n","        if not os.path.exists(dir_path_s):\n","            os.makedirs(dir_path_s)\n","        new_file = dir_path_s + '/' + new_dir+ '_%d.jpg'%i\n","        #print(new_file)\n","        cv2.imwrite(new_file, a)\n","        #print(a)\n","        split_list.append(a)\n","    #print(len(spectral_list))\n","    file_list_1.append(split_list)\n","print(len(file_list_1))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n"]}]}]}